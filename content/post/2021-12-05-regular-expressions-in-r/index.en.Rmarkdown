---
title: Regular Expressions in R
author: twg
date: '2023-11-02'
categories:
  - regex
  - strings
tags:
  - regex
  - strings
slug: regular-expressions-in-r
summary: Working with strings and regex
lastmod: '2021-12-05T22:10:16-08:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
---

```{r, setup, include = FALSE}
pacman::p_load(tidyverse, here, janitor, showtext, knitr)

font_add_google("Raleway", "Raleway")
showtext_auto()

options("width" = 110)
source(here::here("R", "theme_twg.R"))

```

```{r setup-knitr, include = FALSE}
opts_chunk$set(
  eval = TRUE, # Default: TRUE
  include = TRUE, # Default: TRUE
  echo = TRUE, # Default: TRUE
  width = getOption("width"),
  fig.align = "center",
  fig.width = 11.5, # Default: 7
  fig.height = 5.75)
```

## Extracting text before or after symbol or delimiter

```{r}
# timestamp as example 
stamp <- "2017-10-16T12:45:04PM"
# time: extract time after the T
gsub(".*\\T", "", stamp) 
# date: extract everything before the T
gsub("\\T.*", "", stamp) 
```

## Extracting everything up to the Nth occurrence

```{r}
string <- "abc-def-ghi-jkl-mno"

# up to 1st (not including it) 
sub("^(([^-]*-){0}[^-]*).*", "\\1", string)

# up to the 2nd (not including it)
sub("^(([^-]*-){1}[^-]*).*", "\\1", string)

# up to 3rd (not including it)
sub("^(([^-]*-){2}[^-]*).*", "\\1", string)

```

## Extracting before or after the first occurrence of symbol or delimeter

```{r}
string <- "THIS_IS_A_STRING_WITH_A-DASH-SECOND-DASH"
# extract everything after first "-"
sub(".*?-", "", string)
# extract everything up to the first "-"
stringr::str_extract(string, "[^-]+")
# or using sub
sub("-.*", "", string)
```

## Extract the last occurrence in string with multiple occurrences

```{r}
sub(".*[_]", "", "abc_def_ghi_jkl")
```

## Extract everything before last occurrence in string 

```{r}
sub("_[^_]+$", "", "abc_def_ghi_jkl")
```

## Extract everything in between two strings

```{r}
string <- c("The quick brown fox jumped over the lazy dog")
gsub(".*quick (.+) jumped.*", "\\1", string)
```

## Extract hashtags and @handles

```{r}
string <- c("I can't believe @user said #hashtag and #hashtag2")
str_extract_all(string, "@\\w+")
str_extract_all(string, "#\\w+")
```

## Splitting and pulling data after symbols. 

There are also pure regex ways of achieving the same ends, but `stringr` is so easy. 
```{r}
library(stringr)
# assume a url with the following path, and we want to pull out the info after the 2nd slash
urlPath <- "/t5/Announcements-and-Info/Bixby-Button-Short-Press-The-choice-is-yours/m-p/168685/highlight/true#M210"

sapply(str_split(urlPath, "/"), "[[", 3)
```

## Remove commas and convert string to numeric

```{r}
to_num <- function(x) { as.numeric(stringi::stri_replace_all_fixed(x, ",", "")) }
stringnum <- "100,954"
to_num(stringnum)
```

## Add commas and convert numeric to string

```{r}
scales::comma_format()(10000000)
```

## Extract last N and first N characters in string

The ```str_sub``` function from the ```stringr``` package is useful for this. There are three arguments (string, from = start, to = end) - if you don't include "from" and the "to" argument is positive, then it starts from character 1. If "from" is left out and the "to" argument is negative, it starts from the last character in the string. 

```{r}
st <- "Thisstringhasnospaces"
# Last word
str_sub(st, -6)
# First word  
str_sub(st, 1, 4)
# In between
str_sub(st, 5, 10)
```

## Programmatically inserting a line break every N spaces

Found this useful when working with lots of data and using a function to parse the data and plot using ggplot. 
```{r, warning=FALSE}
strfun <- function(str, n) {gsub(paste0("([^ ]+( +[^ ]+){",n-1,"}) +"),
                              "\\1\n", str)}

string <- "As he crossed toward the pharmacy at the corner he involuntarily turned his head because of a burst of light that had ricocheted from his temple..."

strfun(string, 8)

```

If you want to use characters instead... 

## Adding line break after N characters 

```{r}
string <- "As he crossed toward the pharmacy at the corner he involuntarily turned his head because of a burst of light that had ricocheted from his temple..."

paste(strwrap(string, width = 80), collapse = "\n")

```

And if using this on a column in a dataframe

```{r, eval = FALSE}
df |> dplyr::mutate(col = sapply(col, function(x) paste(strwrap(x, 20), collapse = "\n")))
```

## Line breaks after spaces 

```{r, warning = FALSE}
tibble(string = "This is a string") |> 
  mutate(space_2 = glue::glue("{sub('^(\\\\S+\\\\s+\\\\S+\\\\s)', '\\\\1<br>', string, perl = TRUE)}"), # add break to second space
  all_spaces = glue::glue("{gsub(' ', '<br>', string)}"), # add break to any space
  last_space = glue::glue("{sub(' (?=[^ ]*$)', '<br>', string, perl = TRUE)}")) |> 
  gather()
```

## Counting words in a string

Working with strings and trying to count either words or occurrences. 

```{r, warning = FALSE}
library(stringr)
# string with 19 
string <- c("MTD Sales 415  2,667 1  2,014  46 24 52 472  3  2,200  2,256 2,963 25 511  207
            274  14,130")

# this will look for all word characters
str_count(string, '\\w+')

# the above is counting commas as breaks, so remove the comma count
str_count(string, '\\w+') - str_count(string, ",") 
```


## Removing trailing and leading punctuation

In this case, we'll strip out periods before and after.

```{r}
test <- c('.name.A.','name.B','.name.C.')
gsub('^\\.|\\.$', '', test)
```

## Efficiently converting all versions of a word

Working with text and there are different versions and misspellings of a term

```{r}
string <- "i was buffereing but then buffered and buffering on the bluff"
# assuming a consistent word stem
str_replace_all(string, "buffer[a-z]+", "buffer")
```

## Iteratively replacing text in a string using a key 

```{r}
sample_texts <- tibble(text = c("blah-blah-blah-value1_value1-value2_value2",
                                "blah _value1-value2"))

key <- tibble(
  old = c("-value1", "-value2"),
  new = c("_value1", "_value2")
)

sample_texts |> 
  mutate(text = stringi::stri_replace_all_fixed(text, 
                                                pattern = key$old, 
                                                replacement = key$new, 
                                                vectorize_all=FALSE))
```

## Splitting words on space or other character

```{r}
string <- c("apple: banana: orange: kiwi")
str_split(string, boundary('word'))
```

## Splitting a string and keeping the delimiter
 
Using the `separate()` function seems to work well here
```{r}
tmp <- tibble(string = "abc-def-ghi-jkl-mno")
tmp |> separate(string, c("part1", "part2"), "(?=jkl)")
```


## Extracting specific version of a word

Assume we have to find the location of a specific word. In the line below if we search for "string" we're going to get two answers. 
```{r}
string <- tibble(col = c("strings", "stringer", "word", "part", "string"))
string$col[which(str_detect(string$col, "string"))]
# setting the boundary and find only the exact match
string$col[which(str_detect(string$col, "string\\b"))]
```

## Extracting all @mentions 

```{r}
s <- tibble(text = "this is a string, @mention, with a mention")
s |> 
  mutate(mentions = sapply(str_extract_all(text, "@\\w+"), function(x) paste(x, collapse = ", ")),)
```

## Extracting urls into new column in tibble

```{r}
url_pattern <- "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"
tibble(text = c("content with https://www.example.com url", "text in http://www.foo.com", "this string has no url")) |> mutate(url = str_extract(text, url_pattern))
```

